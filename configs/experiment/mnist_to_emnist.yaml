# @package _global_
defaults:
  - override /trainer: gpu
  - override /data: mnist_to_emnist
  - override /callbacks: schrodinger_images
  - override /model: big_images
  - override /logger: default

project_name: 'mnist_to_emnist'
task_name: 'test'
size: 16

trainer:
  val_check_interval: 1000
  log_every_n_steps: 100
  max_epochs: -1
  limit_val_batches: 5

callbacks:
  fid:
    _target_: src.callbacks.CalculateFID
    num_samples: 1000
  
data:
  start_dataset:
    img_size: ${size}
  end_dataset:
    img_size: ${size}
  batch_size: 256
  num_workers: 4

model:
  _target_: src.lightning_modules.FRDSB
  max_gamma: 1.0
  min_gamma: 0.1
  num_steps: 30
  T: 1.5
  cache_max_size: 50
  cache_num_iters: 30
  max_iterations: 10000
  initial_forward_sampling: "ornstein_0"
  max_norm: 1.0

  forward_model:
    in_channels: 1
    out_channels: 1
    down_block_types: ["DownBlock2D", "DownBlock2D", "DownBlock2D"]
    up_block_types: ["UpBlock2D","UpBlock2D", "UpBlock2D"]
    block_out_channels: [32, 32, 64]
  
  backward_model:
    in_channels: 1
    out_channels: 1
    down_block_types: ["DownBlock2D", "DownBlock2D", "DownBlock2D"]
    up_block_types: ["UpBlock2D","UpBlock2D", "UpBlock2D"]
    block_out_channels: [32, 32, 64]

  optimizer:
    lr: 1e-4

  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    _partial_: True
    T_0: 1000
    T_mult: 1
    eta_min: 1.e-6