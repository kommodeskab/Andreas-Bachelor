# @package _global_
defaults:
  - override /trainer: gpu
  - override /logger: default
  - override /callbacks: diffusion
  - override /model: diffusion_model
  - override /data: none

project_name: 'diffusion'
task_name: 'test'

size: 32
animal: 'cat'

callbacks:
  swa:
    _target_: pytorch_lightning.callbacks.StochasticWeightAveraging
    swa_lrs: 1e-2
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: 'val_loss'
    patience: 50
    mode: 'min'

trainer:
  log_every_n_steps: 50
  max_epochs: -1
  val_check_interval: 1.0
  gradient_clip_val: 1.0

data:
  _target_: src.data_modules.BaseDM
  dataset:
    _target_: src.dataset.AFHQDataset
    split: ${animal}
    img_size: ${size}
    train: True
    augment: True
    size_multiplier: 5
  val_dataset:
    _target_: src.dataset.AFHQDataset
    split: ${animal}
    img_size: ${size}
    train: False
  batch_size: 64
  num_workers: 4

model:
  _target_: src.lightning_modules.DDPM
  prediction_type: 'sample'
  num_train_timesteps: 1000
  lr_patience: 20
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    lr: 5.e-5

  model:
    _target_: src.networks.unets.PretrainedUNet2D
    model_id: 'krasnova/ddpm_afhq_64'